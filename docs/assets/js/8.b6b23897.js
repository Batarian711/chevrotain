(window.webpackJsonp=window.webpackJsonp||[]).push([[8],{53:function(t,a,s){"use strict";s.r(a);var n=s(0),e=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,a=t.$createElement,s=t._self._c||a;return s("div",{staticClass:"content"},[s("h1",{attrs:{id:"resolving-lexer-errors"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#resolving-lexer-errors","aria-hidden":"true"}},[t._v("#")]),t._v(" Resolving Lexer Errors")]),s("ul",[s("li",[s("a",{attrs:{href:"#LINE_BREAKS"}},[t._v("No LINE_BREAKS Error.")])]),s("li",[s("a",{attrs:{href:"#ANCHORS"}},[t._v("Unexpected RegExp Anchor Error.")])]),s("li",[s("a",{attrs:{href:"#UNREACHABLE"}},[t._v("Token Can Never Be Matched.")])]),s("li",[s("a",{attrs:{href:"#COMPLEMENT"}},[t._v("Complement Sets cannot be automatically optimized.")])]),s("li",[s("a",{attrs:{href:"#REGEXP_PARSING"}},[t._v("Failed parsing < /.../ > Using the regexp-to-ast library.")])]),s("li",[s("a",{attrs:{href:"#UNICODE_OPTIMIZE"}},[t._v("The regexp unicode flag is not currently supported by the regexp-to-ast library.")])]),s("li",[s("a",{attrs:{href:"#CUSTOM_OPTIMIZE"}},[t._v("TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")])])]),s("h2",{attrs:{id:"LINE_BREAKS"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#LINE_BREAKS","aria-hidden":"true"}},[t._v("#")]),t._v(" No LINE_BREAKS Error")]),s("p",[t._v("A Chevrotain Lexer will by default track the full position information for each token.\nThis includes line and column information.")]),s("p",[t._v("In order to support this the Lexer must be aware of which Tokens may include line terminators.\nThis information must be provided by the lexer's author.")]),s("p",[t._v("This error means that the Lexer has been defined to track line and column information (perhaps by default).\nYet not a single one of the Token definitions passed to it was defined as possibly containing line terminators.")]),s("p",[t._v("To resolve this choose one of the following:")]),s("ol",[s("li",[s("p",[t._v("Disable the line and column position tracking using the "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/ilexerconfig.html#positiontracking",target:"_blank",rel:"noopener noreferrer"}},[t._v("positionTracking")]),t._v(" configuration option.")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),s("span",{attrs:{class:"token comment"}},[t._v("/*, ... */")]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    positionTracking"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"onlyOffset"')]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),s("li",[s("p",[t._v("Mark the Tokens which may include a line terminator with a line_breaks flag.")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// Using createToken API")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"Whitespace"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/\\s+/")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    line_breaks"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// or in ES2015 syntax with static properties")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("class")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("Whitespace")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("extends")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Token")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\nWhitespace"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token constant"}},[t._v("PATTERN")]),t._v(" "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/\\s+/")]),t._v("\nWhitespace"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token constant"}},[t._v("LINE_BREAKS")]),t._v(" "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token boolean"}},[t._v("true")]),t._v("\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myTokens "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("IntegerLiteral"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" StringLiteral"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" WhiteSpace "),s("span",{attrs:{class:"token comment"}},[t._v("/*, ... */")]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("myTokens"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("ul",[s("li",[s("p",[t._v("Note that the definition of what constitutes a line terminator is controlled by the\n"),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/ilexerconfig.html#lineTerminatorsPattern",target:"_blank",rel:"noopener noreferrer"}},[t._v("lineTerminatorsPattern")]),t._v(" lexer configuration property.")])]),s("li",[s("p",[t._v("Also note that multi-line tokens such as some types of comments and string literals tokens may contain\nline terminators, if your language includes such tokens they must also be marked with the line_breaks flag.")])])])])]),s("h2",{attrs:{id:"ANCHORS"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#ANCHORS","aria-hidden":"true"}},[t._v("#")]),t._v(" Unexpected RegExp Anchor Error")]),s("p",[t._v("A Token RegExp pattern used in a chevrotain lexer may not use the start/end of input anchors ('$' and '^').")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// Using createToken API")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Whitespace "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"Integer"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// invalid pattern using both anchors")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/^\\d+$/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("This will be checked for during the initialization of the lexer.\nUnfortunately, this validation can detect false positives when the anchor characters\nare used in certain regExp contexts, for example:")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" createToken "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("createToken\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" semVer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"semVer"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v('// will match semantic versions such as: "1.0.2", "^0.3.9"')]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// inside a character set ([...]) the carat ('^') character does not act as an anchor.")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// yet it would still cause the validation to fail.")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[~^]?\\d+\\.\\d+\\.\\d+/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// will throw an error")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("semVer"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("It is possible to workaround this problem by simply "),s("strong",[t._v("escaping")]),t._v(" the the offending carat or dollar sign.")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" semVer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"semVer"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[~\\^]?\\d+\\.\\d+\\.\\d+/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h2",{attrs:{id:"UNREACHABLE"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#UNREACHABLE","aria-hidden":"true"}},[t._v("#")]),t._v(" Token can never be matched")]),s("p",[t._v("This error means that A Token type can never be successfully matched as\na "),s("strong",[t._v("previous")]),t._v(" Token type in the lexer definition will "),s("strong",[t._v("always")]),t._v(" matched instead.\nThis happens because the default behavior of Chevrotain is to attempt to match\ntokens "),s("strong",[t._v("by the order")]),t._v(" described in the lexer definition.")]),s("p",[t._v("For example:")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" ForKeyword "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"ForKeyword"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/for/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Identifier "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"Identifier"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[a-zA-z]+/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// Will throw Token <ForKeyword> can never be matched...")]),t._v("\n"),s("span",{attrs:{class:"token comment"}},[t._v('// Because the input "for" is also a valid identifier')]),t._v("\n"),s("span",{attrs:{class:"token comment"}},[t._v("// and matching an identifier will be attempted first.")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("Identifier"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" ForKeyword"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("ul",[s("li",[t._v("Note that this validation is limited to simple patterns such as keywords\nThe more general case of any pattern being a strict subset of a preceding pattern\nwill require much more in depth RegExp analysis capabilities.")])]),s("p",[t._v("To resolve this simply re-arrange the order of Token types in the lexer\ndefinition such that the more specific Token types will be listed first.")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token comment"}},[t._v("// Identifier is now listed as the last Token type.")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("Note that the solution provided above will create a new problem.\nAny identifier "),s("strong",[t._v("starting with")]),t._v(' "for" will be lexed as '),s("strong",[t._v("two separate")]),t._v(" tokens,\na ForKeyword and an identifier. For example:")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" myLexer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token keyword"}},[t._v("new")]),t._v(" "),s("span",{attrs:{class:"token class-name"}},[t._v("chevrotain"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),t._v("Lexer")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),t._v("ForKeyword"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" Identifier"),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n\n"),s("span",{attrs:{class:"token comment"}},[t._v("// [")]),t._v("\n"),s("span",{attrs:{class:"token comment"}},[t._v('//    {image:"for"}')]),t._v("\n"),s("span",{attrs:{class:"token comment"}},[t._v('//    {image:"ward"}')]),t._v("\n"),s("span",{attrs:{class:"token comment"}},[t._v("// ]")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" tokensResult "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" myLexer"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token function"}},[t._v("tokenize")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token string"}},[t._v('"forward"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("To resolve this second problem see how to prefer the "),s("strong",[t._v("longest match")]),t._v("\nas demonstrated in the "),s("a",{attrs:{href:"https://github.com/SAP/Chevrotain/blob/master/examples/lexer/keywords_vs_identifiers/keywords_vs_identifiers.js",target:"_blank",rel:"noopener noreferrer"}},[t._v("keywords vs identifiers example")])]),s("h2",{attrs:{id:"COMPLEMENT"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#COMPLEMENT","aria-hidden":"true"}},[t._v("#")]),t._v(" Complement Sets cannot be automatically optimized")]),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode")]),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),s("p",[t._v("When a TokenType pattern uses a regExp complement Set as a potential "),s("strong",[t._v("first")]),t._v(" character\nthe optimization is skipped as translating a complement set to a regular set requires too many cpu cycles\nduring the Lexer's initialization.")]),s("p",[t._v("For example an XML Text is defined by "),s("strong",[t._v("everything")]),t._v(" except a closing tag.")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"XMLText"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("This means that there are "),s("strong",[t._v("65533")]),t._v(" (65535 - 2) possible starting charCodes\nFor an XMLText token.")]),s("p",[t._v('If the use of these optimizations is desired and the startup resources cost is acceptable\nIt is possilbe to enable the optimizations by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint")]),t._v('" property.\ne.g:')]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" hints "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{attrs:{class:"token keyword"}},[t._v("for")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token keyword"}},[t._v("let")]),t._v(" i "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("0")]),s("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i "),s("span",{attrs:{class:"token operator"}},[t._v("<=")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("65535")]),s("span",{attrs:{class:"token punctuation"}},[t._v(";")]),t._v(" i"),s("span",{attrs:{class:"token operator"}},[t._v("++")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// 38 is '<' and 60 is '&'")]),t._v("\n    "),s("span",{attrs:{class:"token keyword"}},[t._v("if")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i "),s("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("38")]),t._v(" "),s("span",{attrs:{class:"token operator"}},[t._v("||")]),t._v(" i "),s("span",{attrs:{class:"token operator"}},[t._v("!==")]),t._v(" "),s("span",{attrs:{class:"token number"}},[t._v("60")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        hints"),s("span",{attrs:{class:"token punctuation"}},[t._v(".")]),s("span",{attrs:{class:"token function"}},[t._v("push")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("i"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n    "),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n\n"),s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" XMLText "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"XMLText"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[^<&]+/")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    start_chars_hint"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" hints\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("Please Note that filling such an array "),s("a",{attrs:{href:"https://jsperf.com/fill-16-bits",target:"_blank",rel:"noopener noreferrer"}},[t._v("can take over 1ms")]),t._v(" on a modern machine.\nSo if you are only parsing small inputs and/or starting a new process for each\nparser invocation the added initilization cost may be counter productive.")]),s("h2",{attrs:{id:"REGEXP_PARSING"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#REGEXP_PARSING","aria-hidden":"true"}},[t._v("#")]),t._v(" Failed parsing < /.../ > Using the regexp-to-ast library")]),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode")]),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),s("p",[t._v("This analysis is implemented using the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast")]),t._v(" library.\nThis error usally indicates a bug in the regexp-to-ast library.\nThe impact is that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, only slower...")]),s("p",[t._v("Please open a bug for the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast")]),t._v(" library.\nThis issue can be "),s("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint")]),t._v('" property.')]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" Integer "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"Integer"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// lets assume that this pattern caused an error in regexp-to-ast")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/[1-9]\\d*/")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// by explicitly providing the first possible characters of this pattern")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// the analysis by the regexp-to-ast library will be skipped")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// and the optimization can be enabled.")]),t._v("\n    start_chars_hint"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{attrs:{class:"token string"}},[t._v('"1"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"2"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"3"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"4"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"5"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"6"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"7"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"8"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"9"')]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h2",{attrs:{id:"UNICODE_OPTIMIZE"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#UNICODE_OPTIMIZE","aria-hidden":"true"}},[t._v("#")]),t._v(" The regexp unicode flag is not currently supported by the regexp-to-ast library")]),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode")]),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),s("p",[t._v("This analysis is implemented using the "),s("a",{attrs:{href:"https://github.com/bd82/regexp-to-ast",target:"_blank",rel:"noopener noreferrer"}},[t._v("regexp-to-ast")]),t._v(" library.\nThis library currently does not support the "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/RegExp/unicode",target:"_blank",rel:"noopener noreferrer"}},[t._v("unicode regexp flag")]),t._v("\nThe impact is that the optimization described above would become disabled.\nLexing and Parsing will still work correctly, just slower...")]),s("p",[t._v("This issue can be "),s("strong",[t._v("worked around")]),t._v(' by explicitly providing a "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint")]),t._v('" property.')]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token comment"}},[t._v("// '💩' character")]),t._v("\n"),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"PileOfPoo"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// \\u{xxxxx} 32bit unicode escape can only be used with the /u flag enabled.")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token regex"}},[t._v("/\\u{1F4A9}/u")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// The '💩' character is represented by surrogate pairs: '\\uD83D\\uDCA9'")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// the start_chars_hint should only be provided the first of the pair.")]),t._v("\n    start_chars_hint"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{attrs:{class:"token number"}},[t._v("55357")]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v("Another way to "),s("strong",[t._v("work around")]),t._v(" the issue is to define the pattern as a string literal.\nAs that kind can be trivially optimized.\nThis is naturally only relevant for simple patterns.\nFor example:")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"LCurley"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),s("span",{attrs:{class:"token comment"}},[t._v("// note that the pattern is a string literal, not a regExp literal.")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"{"')]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("h2",{attrs:{id:"CUSTOM_OPTIMIZE"}},[s("a",{staticClass:"header-anchor",attrs:{href:"#CUSTOM_OPTIMIZE","aria-hidden":"true"}},[t._v("#")]),t._v(" TokenType <...> is using a custom token pattern without providing <char_start_hint> parameter")]),s("p",[t._v("The Chevrotain Lexer performs optimizations by filtering the potential token matchs\nusing the next "),s("a",{attrs:{href:"https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/charCodeAt",target:"_blank",rel:"noopener noreferrer"}},[t._v("charCode")]),t._v(" to be consumed.\nTo apply this optimization the first possible charCodes for "),s("strong",[t._v("every")]),t._v(" TokenType must be identified.")]),s("p",[t._v("This information cannot be automatically computed for "),s("a",{attrs:{href:"https://sap.github.io/chevrotain/docs/guide/custom_token_patterns.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("custom token patterns")]),t._v("\nand "),s("strong",[t._v("should")]),t._v(' therefore be explicitly provided using the "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint")]),t._v('" property.')]),s("p",[t._v("For example:")]),s("pre",{pre:!0,attrs:{class:"language-javascript"}},[s("code",[s("span",{attrs:{class:"token keyword"}},[t._v("const")]),t._v(" IntegerToken "),s("span",{attrs:{class:"token operator"}},[t._v("=")]),t._v(" "),s("span",{attrs:{class:"token function"}},[t._v("createToken")]),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    name"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"IntegerToken"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    pattern"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        exec"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("(")]),t._v("text"),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" offset"),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v(" "),s("span",{attrs:{class:"token operator"}},[t._v("=>")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n            "),s("span",{attrs:{class:"token comment"}},[t._v("/* ... */")]),t._v("\n        "),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    start_chars_hint"),s("span",{attrs:{class:"token punctuation"}},[t._v(":")]),t._v(" "),s("span",{attrs:{class:"token punctuation"}},[t._v("[")]),s("span",{attrs:{class:"token string"}},[t._v('"1"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"2"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"3"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"4"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"5"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"6"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"7"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"8"')]),s("span",{attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),s("span",{attrs:{class:"token string"}},[t._v('"9"')]),s("span",{attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n"),s("span",{attrs:{class:"token punctuation"}},[t._v("}")]),s("span",{attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])]),s("p",[t._v('Providing the "'),s("a",{attrs:{href:"https://sap.github.io/chevrotain/documentation/3_2_0/interfaces/itokenconfig.html#start_chars_hint",target:"_blank",rel:"noopener noreferrer"}},[t._v("start_chars_hint")]),t._v('" property is '),s("strong",[t._v("not")]),t._v(" mandatory.\nIt will only enable performance optimizations in the lexer.")])])}],!1,null,null,null);a.default=e.exports}}]);